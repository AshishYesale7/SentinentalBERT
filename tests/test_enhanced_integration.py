#!/usr/bin/env python3
"""
Enhanced Integration Test for InsideOut Platform
Tests Indian legal framework, multilingual support, and global platform integration
"""

import sys
import os
import json
from datetime import datetime
import traceback

# Add services to path
sys.path.append(os.path.join(os.path.dirname(__file__), 'services'))

def test_legal_framework():
    """Test Indian legal framework compliance"""
    print("üîç Testing Indian Legal Framework...")
    
    try:
        from services.legal_compliance.indian_legal_framework import (
            IndianLegalFramework, LegalAuthority, EvidenceType
        )
        
        # Initialize framework
        legal_framework = IndianLegalFramework()
        
        # Test legal authorization creation
        auth_data = {
            "authority_type": "magistrate_warrant",
            "issuing_authority": "Chief Metropolitan Magistrate, Delhi",
            "case_number": "FIR_001_2025_CYBER_CELL",
            "sections_invoked": ["IT_Act_66", "IT_Act_67", "CrPC_156", "Evidence_Act_65B"],
            "validity_start": "2025-09-21T00:00:00",
            "validity_end": "2025-12-21T23:59:59",
            "scope_description": "Investigation of viral misinformation campaign",
            "target_platforms": ["twitter", "facebook", "instagram"],
            "target_accounts": ["@suspicious_account1", "@viral_spreader2"],
            "authorized_officers": ["Inspector_Sharma", "SI_Patel"]
        }
        
        authorization = legal_framework.create_legal_authorization(auth_data)
        
        if not authorization:
            print("‚ùå Legal authorization creation failed")
            return False
        
        print(f"‚úÖ Legal authorization created: {authorization.auth_id}")
        
        # Test evidence collection
        evidence = legal_framework.collect_digital_evidence(
            content="Sample viral post content for investigation #ViralContent #India",
            platform="twitter",
            evidence_type=EvidenceType.ELECTRONIC_RECORD,
            collecting_officer="Inspector_Sharma",
            authorization_id=authorization.auth_id,
            metadata={"post_id": "12345", "timestamp": "2025-09-21T10:30:00", "viral_score": 0.85}
        )
        
        if not evidence:
            print("‚ùå Evidence collection failed")
            return False
        
        print(f"‚úÖ Evidence collected: {evidence.evidence_id}")
        
        # Test evidence integrity verification
        is_valid, message = legal_framework.verify_evidence_integrity(evidence.evidence_id)
        
        if not is_valid:
            print(f"‚ùå Evidence integrity verification failed: {message}")
            return False
        
        print(f"‚úÖ Evidence integrity verified: {message}")
        
        # Test chain of custody
        custody_added = legal_framework.add_custody_entry(
            evidence.evidence_id,
            "SI_Patel",
            "analyzed",
            "Forensic analysis completed"
        )
        
        if not custody_added:
            print("‚ùå Chain of custody entry failed")
            return False
        
        print("‚úÖ Chain of custody entry added")
        
        # Test court report generation
        report = legal_framework.generate_court_report("FIR_001_2025_CYBER_CELL")
        
        if not report or report['total_evidence_items'] == 0:
            print("‚ùå Court report generation failed")
            return False
        
        print(f"‚úÖ Court report generated with {report['total_evidence_items']} evidence items")
        print(f"   Compliance status: {report['compliance_status']['overall_compliance']}")
        
        return True
        
    except Exception as e:
        print(f"‚ùå Legal framework test failed: {str(e)}")
        traceback.print_exc()
        return False

def test_multilingual_support():
    """Test enhanced multilingual support"""
    print("\nüåê Testing Enhanced Multilingual Support...")
    
    try:
        from services.multilingual.enhanced_language_support import EnhancedLanguageSupport
        
        # Initialize language support
        lang_support = EnhancedLanguageSupport()
        
        # Test language detection
        test_texts = [
            ("‡§Ø‡§π ‡§è‡§ï ‡§π‡§ø‡§Ç‡§¶‡•Ä ‡§µ‡§æ‡§ï‡•ç‡§Ø ‡§π‡•à ‡§ú‡•ã ‡§µ‡§æ‡§Ø‡§∞‡§≤ ‡§π‡•ã ‡§∞‡§π‡§æ ‡§π‡•à‡•§", "hi"),
            ("‡¶è‡¶ü‡¶ø ‡¶è‡¶ï‡¶ü‡¶ø ‡¶¨‡¶æ‡¶Ç‡¶≤‡¶æ ‡¶¨‡¶æ‡¶ï‡ßç‡¶Ø ‡¶Ø‡¶æ ‡¶≠‡¶æ‡¶á‡¶∞‡¶æ‡¶≤ ‡¶π‡¶ö‡ßç‡¶õ‡ßá‡•§", "bn"),
            ("‡Æá‡Æ§‡ØÅ ‡Æí‡Æ∞‡ØÅ ‡Æ§‡ÆÆ‡Æø‡Æ¥‡Øç ‡Æµ‡Ææ‡Æï‡Øç‡Æï‡Æø‡ÆØ‡ÆÆ‡Øç ‡Æµ‡Øà‡Æ∞‡Æ≤‡Ææ‡Æï‡Æø‡Æ±‡Æ§‡ØÅ‡•§", "ta"),
            ("‡∞á‡∞¶‡∞ø ‡∞µ‡±à‡∞∞‡∞≤‡±ç ‡∞Ö‡∞µ‡±Å‡∞§‡±Å‡∞®‡±ç‡∞® ‡∞§‡±Ü‡∞≤‡±Å‡∞ó‡±Å ‡∞µ‡∞æ‡∞ï‡±ç‡∞Ø‡∞Ç.", "te"),
            ("This is an English sentence going viral.", "en")
        ]
        
        detection_success = 0
        for text, expected_lang in test_texts:
            detected = lang_support.detect_language(text)
            
            if detected and detected[0][0] == expected_lang:
                print(f"‚úÖ Language detection successful: {expected_lang}")
                detection_success += 1
            else:
                print(f"‚ùå Language detection failed for {expected_lang}: {detected}")
        
        if detection_success < len(test_texts) * 0.8:  # 80% success rate
            print(f"‚ùå Language detection success rate too low: {detection_success}/{len(test_texts)}")
            return False
        
        print(f"‚úÖ Language detection success rate: {detection_success}/{len(test_texts)}")
        
        # Test UI translations
        test_keys = ["dashboard_title", "government_text", "active_clusters", "evidence_packages"]
        
        for lang_code in ["hi", "bn", "ta", "te", "en"]:
            translations_found = 0
            for key in test_keys:
                translation = lang_support.get_ui_translation(lang_code, key)
                if translation and translation != key:  # Translation found and not just the key
                    translations_found += 1
            
            if translations_found > 0:
                print(f"‚úÖ UI translations available for {lang_code}: {translations_found}/{len(test_keys)}")
            else:
                print(f"‚ö†Ô∏è No UI translations found for {lang_code}")
        
        # Test multilingual content analysis
        mixed_content = "Breaking news! ‡§Ø‡§π ‡§¨‡§π‡•Å‡§§ ‡§Æ‡§π‡§§‡•ç‡§µ‡§™‡•Ç‡§∞‡•ç‡§£ ‡§ñ‡§¨‡§∞ ‡§π‡•à‡•§ This is going viral #ViralContent #India"
        analysis = lang_support.analyze_multilingual_content(mixed_content)
        
        if not analysis or not analysis.get('detected_languages'):
            print("‚ùå Multilingual content analysis failed")
            return False
        
        print(f"‚úÖ Multilingual analysis successful: {len(analysis['detected_languages'])} languages detected")
        print(f"   Primary language: {analysis['primary_language']}")
        print(f"   Is multilingual: {analysis['is_multilingual']}")
        
        # Test supported languages
        supported_languages = lang_support.get_supported_languages()
        
        if len(supported_languages) < 5:
            print(f"‚ùå Insufficient language support: {len(supported_languages)} languages")
            return False
        
        print(f"‚úÖ Language support comprehensive: {len(supported_languages)} languages supported")
        
        return True
        
    except Exception as e:
        print(f"‚ùå Multilingual support test failed: {str(e)}")
        traceback.print_exc()
        return False

def test_global_platform_support():
    """Test global platform support"""
    print("\nüåç Testing Global Platform Support...")
    
    try:
        from services.platforms.global_platform_support import GlobalPlatformSupport
        
        # Initialize platform support
        platform_support = GlobalPlatformSupport()
        
        # Test supported platforms
        all_platforms = platform_support.get_supported_platforms()
        
        if len(all_platforms) < 5:
            print(f"‚ùå Insufficient platform support: {len(all_platforms)} platforms")
            return False
        
        print(f"‚úÖ Platform support comprehensive: {len(all_platforms)} platforms supported")
        
        # Test Indian platforms
        indian_platforms = platform_support.get_indian_platforms()
        
        expected_indian_platforms = ["koo", "sharechat", "twitter", "facebook", "instagram"]
        indian_found = sum(1 for platform in expected_indian_platforms if platform in indian_platforms)
        
        if indian_found < 3:
            print(f"‚ùå Insufficient Indian platform support: {indian_found} platforms")
            return False
        
        print(f"‚úÖ Indian platform support good: {indian_found}/{len(expected_indian_platforms)} platforms")
        
        # Test content metadata extraction
        test_contents = [
            ("twitter", "Breaking news! #ViralContent spreading across social media @everyone please share #India"),
            ("facebook", "Shared this important post about current events. Please like and share! #Trending"),
            ("koo", "‡§≠‡§æ‡§∞‡§§ ‡§Æ‡•á‡§Ç ‡§µ‡§æ‡§Ø‡§∞‡§≤ ‡§π‡•ã ‡§∞‡§π‡§æ ‡§π‡•à ‡§Ø‡§π ‡§∏‡§Æ‡§æ‡§ö‡§æ‡§∞ #‡§∏‡§Æ‡§æ‡§ö‡§æ‡§∞ #‡§≠‡§æ‡§∞‡§§ @user123"),
            ("instagram", "Check out this amazing content! #viral #trending #photography @photographer"),
            ("youtube", "New video uploaded! Don't forget to like and subscribe #youtube #content")
        ]
        
        extraction_success = 0
        for platform, content in test_contents:
            if platform in all_platforms:
                metadata = platform_support.extract_content_metadata(platform, content, {
                    "like_count": 1500,
                    "share_count": 300,
                    "comment_count": 150
                })
                
                if metadata and metadata.get('platform') == platform:
                    print(f"‚úÖ Content extraction successful for {platform}")
                    print(f"   Viral potential: {metadata.get('viral_potential', {}).get('score', 0):.2f}")
                    print(f"   Classification: {metadata.get('content_classification', 'unknown')}")
                    extraction_success += 1
                else:
                    print(f"‚ùå Content extraction failed for {platform}")
        
        if extraction_success < len(test_contents) * 0.8:
            print(f"‚ùå Content extraction success rate too low: {extraction_success}/{len(test_contents)}")
            return False
        
        print(f"‚úÖ Content extraction success rate: {extraction_success}/{len(test_contents)}")
        
        # Test platform-specific features
        platform_features_tested = 0
        
        for platform_id, platform_config in list(all_platforms.items())[:5]:
            features = {
                "hashtags": platform_config.get('supports_hashtags', False),
                "mentions": platform_config.get('supports_mentions', False),
                "reposting": platform_config.get('supports_reposting', False),
                "api": platform_config.get('api_available', False)
            }
            
            feature_count = sum(features.values())
            if feature_count >= 2:  # At least 2 features supported
                platform_features_tested += 1
                print(f"‚úÖ {platform_config['name']} features: {feature_count}/4 supported")
        
        if platform_features_tested < 3:
            print(f"‚ùå Insufficient platform feature support: {platform_features_tested} platforms")
            return False
        
        print(f"‚úÖ Platform features well supported: {platform_features_tested} platforms with good feature coverage")
        
        return True
        
    except Exception as e:
        print(f"‚ùå Global platform support test failed: {str(e)}")
        traceback.print_exc()
        return False

def test_integration():
    """Test integration between all components"""
    print("\nüîó Testing Component Integration...")
    
    try:
        from services.legal_compliance.indian_legal_framework import IndianLegalFramework, EvidenceType
        from services.multilingual.enhanced_language_support import EnhancedLanguageSupport
        from services.platforms.global_platform_support import GlobalPlatformSupport
        
        # Initialize all services
        legal_framework = IndianLegalFramework()
        lang_support = EnhancedLanguageSupport()
        platform_support = GlobalPlatformSupport()
        
        print("‚úÖ All services initialized successfully")
        
        # Test integrated workflow
        # 1. Create legal authorization
        auth_data = {
            "authority_type": "magistrate_warrant",
            "issuing_authority": "Chief Metropolitan Magistrate, Mumbai",
            "case_number": "FIR_002_2025_INTEGRATION_TEST",
            "sections_invoked": ["IT_Act_66", "CrPC_156"],
            "validity_start": "2025-09-21T00:00:00",
            "validity_end": "2025-12-21T23:59:59",
            "scope_description": "Integration test for viral content analysis",
            "target_platforms": ["twitter", "koo", "facebook"],
            "authorized_officers": ["Inspector_Integration"]
        }
        
        authorization = legal_framework.create_legal_authorization(auth_data)
        if not authorization:
            print("‚ùå Integration test: Legal authorization failed")
            return False
        
        print("‚úÖ Integration test: Legal authorization created")
        
        # 2. Analyze multilingual viral content
        viral_content = "üö® Breaking: ‡§Æ‡§π‡§§‡•ç‡§µ‡§™‡•Ç‡§∞‡•ç‡§£ ‡§ñ‡§¨‡§∞! This content is going viral across platforms #BreakingNews #India @everyone"
        
        # Language analysis
        lang_analysis = lang_support.analyze_multilingual_content(viral_content)
        if not lang_analysis:
            print("‚ùå Integration test: Language analysis failed")
            return False
        
        print(f"‚úÖ Integration test: Language analysis completed - {len(lang_analysis['detected_languages'])} languages")
        
        # Platform analysis
        platform_metadata = platform_support.extract_content_metadata("twitter", viral_content, {
            "retweet_count": 2500,
            "like_count": 8900,
            "reply_count": 450
        })
        
        if not platform_metadata:
            print("‚ùå Integration test: Platform analysis failed")
            return False
        
        print(f"‚úÖ Integration test: Platform analysis completed - Viral score: {platform_metadata.get('viral_potential', {}).get('score', 0):.2f}")
        
        # 3. Collect evidence with all metadata
        combined_metadata = {
            **platform_metadata.get('viral_metrics', {}),
            "language_analysis": lang_analysis,
            "platform_analysis": platform_metadata,
            "integration_test": True
        }
        
        evidence = legal_framework.collect_digital_evidence(
            content=viral_content,
            platform="twitter",
            evidence_type=EvidenceType.ELECTRONIC_RECORD,
            collecting_officer="Inspector_Integration",
            authorization_id=authorization.auth_id,
            metadata=combined_metadata
        )
        
        if not evidence:
            print("‚ùå Integration test: Evidence collection failed")
            return False
        
        print("‚úÖ Integration test: Evidence collection with integrated metadata successful")
        
        # 4. Generate comprehensive report
        report = legal_framework.generate_court_report("FIR_002_2025_INTEGRATION_TEST")
        
        if not report or report['total_evidence_items'] == 0:
            print("‚ùå Integration test: Report generation failed")
            return False
        
        print("‚úÖ Integration test: Comprehensive report generated successfully")
        
        # 5. Test cross-platform analysis
        cross_platform_data = [
            {
                "platform": "twitter",
                "viral_potential": {"score": 0.85},
                "viral_metrics": {"retweet_count": 2500, "like_count": 8900},
                "timestamp": "2025-09-21T10:00:00"
            },
            {
                "platform": "facebook", 
                "viral_potential": {"score": 0.72},
                "viral_metrics": {"share_count": 1200, "like_count": 5600},
                "timestamp": "2025-09-21T10:15:00"
            },
            {
                "platform": "koo",
                "viral_potential": {"score": 0.68},
                "viral_metrics": {"rekoo_count": 800, "like_count": 3400},
                "timestamp": "2025-09-21T10:30:00"
            }
        ]
        
        cross_analysis = platform_support.analyze_cross_platform_spread(cross_platform_data)
        
        if not cross_analysis or cross_analysis.get('total_platforms', 0) < 3:
            print("‚ùå Integration test: Cross-platform analysis failed")
            return False
        
        print(f"‚úÖ Integration test: Cross-platform analysis successful - {cross_analysis['total_platforms']} platforms")
        print(f"   Primary platform: {cross_analysis['primary_platform']}")
        print(f"   Cross-platform score: {cross_analysis['cross_platform_score']:.2f}")
        
        return True
        
    except Exception as e:
        print(f"‚ùå Integration test failed: {str(e)}")
        traceback.print_exc()
        return False

def run_comprehensive_test():
    """Run comprehensive test suite"""
    print("üöÄ Starting Enhanced InsideOut Platform Integration Tests")
    print("=" * 70)
    
    test_results = {
        "legal_framework": False,
        "multilingual_support": False,
        "global_platform_support": False,
        "integration": False
    }
    
    # Run individual component tests
    test_results["legal_framework"] = test_legal_framework()
    test_results["multilingual_support"] = test_multilingual_support()
    test_results["global_platform_support"] = test_global_platform_support()
    
    # Run integration test only if all components pass
    if all([test_results["legal_framework"], test_results["multilingual_support"], test_results["global_platform_support"]]):
        test_results["integration"] = test_integration()
    else:
        print("\n‚ö†Ô∏è Skipping integration test due to component failures")
    
    # Generate test report
    print("\n" + "=" * 70)
    print("üìä TEST RESULTS SUMMARY")
    print("=" * 70)
    
    total_tests = len(test_results)
    passed_tests = sum(test_results.values())
    
    for test_name, result in test_results.items():
        status = "‚úÖ PASSED" if result else "‚ùå FAILED"
        print(f"{test_name.replace('_', ' ').title():<30} {status}")
    
    print("-" * 70)
    print(f"Overall Success Rate: {passed_tests}/{total_tests} ({(passed_tests/total_tests)*100:.1f}%)")
    
    if passed_tests == total_tests:
        print("\nüéâ ALL TESTS PASSED! Enhanced InsideOut Platform is ready for deployment.")
        deployment_status = "READY"
    elif passed_tests >= total_tests * 0.75:
        print("\n‚ö†Ô∏è MOSTLY SUCCESSFUL! Platform is functional with minor issues.")
        deployment_status = "READY_WITH_WARNINGS"
    else:
        print("\n‚ùå SIGNIFICANT ISSUES FOUND! Platform needs fixes before deployment.")
        deployment_status = "NOT_READY"
    
    # Generate test report file
    test_report = {
        "test_timestamp": datetime.now().isoformat(),
        "test_results": test_results,
        "success_rate": f"{(passed_tests/total_tests)*100:.1f}%",
        "deployment_status": deployment_status,
        "total_tests": total_tests,
        "passed_tests": passed_tests,
        "failed_tests": total_tests - passed_tests,
        "components_tested": [
            "Indian Legal Framework (IT Act, CrPC, Evidence Act)",
            "Enhanced Multilingual Support (5+ Indian languages)",
            "Global Platform Support (8+ platforms)",
            "Cross-component Integration"
        ],
        "features_verified": [
            "Legal authorization creation and validation",
            "Digital evidence collection with chain of custody",
            "Section 65B certificate generation",
            "Multi-language content detection and analysis",
            "UI translation system",
            "Global platform content extraction",
            "Viral potential calculation",
            "Cross-platform spread analysis",
            "Integrated workflow processing"
        ]
    }
    
    with open("enhanced_integration_test_report.json", "w") as f:
        json.dump(test_report, f, indent=2)
    
    print(f"\nüìÑ Detailed test report saved to: enhanced_integration_test_report.json")
    
    return deployment_status == "READY"

if __name__ == "__main__":
    success = run_comprehensive_test()
    exit(0 if success else 1)